{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dir = './models/*'\n",
    "model_files = glob.glob(dir)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(\n",
    "          input_size=n_features,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "          input_size=self.hidden_dim,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape((1, self.seq_len, self.n_features))\n",
    "        \n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        \n",
    "        return hidden_n.reshape((self.seq_len, self.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "       \n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=input_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_len, self.n_features)\n",
    "        x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "        \n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        x = x.reshape((self.n_features, self.hidden_dim))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(RecurrentAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/model_onehot_x1data_L1_epoch200.pth'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onehot_L1 = torch.load(model_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(string.ascii_uppercase)\n",
    "chr2index = {alpha[i]:i for i in range(len(alpha))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chr2OH(alphabet):\n",
    "    oh = [0 for i in range(len(alpha))]\n",
    "    index = chr2index[alphabet]\n",
    "    oh[index] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/fsm/0graph1.txt',\n",
       " './datasets/fsm/0graph0.txt',\n",
       " './datasets/fsm/0graph2.txt']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './datasets/fsm/0graph*'\n",
    "# file read\n",
    "all_names = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "data_length = len(glob.glob(dir))\n",
    "\n",
    "files = glob.glob(dir)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(dir)\n",
    "for file in files:\n",
    "    datasets = []\n",
    "    for rf in open(file, 'r'):\n",
    "        (u, v, w) = rf[1:-2].split(', ')\n",
    "        datasets.append(chr2OH(u[1]) + chr2OH(v[1]) +[float(w)])\n",
    "        #datasets.append([chr2index[u[1]], chr2index[v[1]], float(w)])\n",
    "    sequence_length.append(len(datasets))\n",
    "    all_data.append(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 5\n",
    "#zeros = np.zeros(53)\n",
    "zeros = [0 for i in range(53)]\n",
    "for ind, data in enumerate(all_data):\n",
    "    if len(data) != max_sequence_length:\n",
    "        for i in range(len(data), max_sequence_length):\n",
    "            all_data[ind].append(zeros)\n",
    "       \n",
    "\n",
    "all_data = np.array([np.array(arr) for arr in all_data])\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_d = []\n",
    "for ind, data in enumerate(all_data):\n",
    "    all_d.append(data.flatten())\n",
    "all_d\n",
    "len(all_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset_1(nparrays):\n",
    "    dataset = [torch.tensor(s).unsqueeze(0).float() for s in nparrays]\n",
    "  #step_per_epoch, seq_len, llen, n_features = torch.stack(dataset).shape\n",
    "    #n_seq, m ,seq_len, n_features = print(torch.stack(dataset).shape)\n",
    "    print(torch.stack(dataset).shape)\n",
    "    n_seq, seq_len, n_features = torch.stack(dataset).shape\n",
    "    #print( n_seq, m , seq_len, n_features )\n",
    "    return dataset, seq_len, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 265])\n"
     ]
    }
   ],
   "source": [
    "ts, seq_len_1d , n_features_1d  = create_dataset_1(all_d)\n",
    "ss  = [torch.tensor(s).unsqueeze(0).float() for s in all_d]\n",
    "T = ts[1]\n",
    "F = ts[0]\n",
    "M = ts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, 30.9065,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, 10.9700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset):\n",
    "    predictions, losses = [], []\n",
    "    criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        for seq_true in dataset:\n",
    "            seq_true = seq_true.to(device)\n",
    "            seq_pred = model(seq_true)\n",
    "            print(seq_pred.shape)\n",
    "            loss = criterion(seq_pred, seq_true)\n",
    "            print(loss)\n",
    "            print(seq_pred.cpu().numpy().flatten())\n",
    "            predictions.append(seq_pred.cpu().numpy().flatten())\n",
    "            losses.append(loss.item())\n",
    "    return predictions, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([265, 265])\n",
      "tensor(0.0753, device='cuda:0')\n",
      "[ 9.0990865e-01  1.3487136e-02  5.1256940e-03 ... -7.9503423e-04\n",
      " -2.3353663e-03  2.4692950e+00]\n"
     ]
    }
   ],
   "source": [
    "prT, _ = predict(model_onehot_L1, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([265, 265])\n",
      "tensor(0.6906, device='cuda:0')\n",
      "[ 0.70929873  0.12725899  0.02833471 ... -0.01676553 -0.03422892\n",
      "  7.3599625 ]\n"
     ]
    }
   ],
   "source": [
    "prF, _ = predict(model_onehot_L1, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([265, 265])\n",
      "tensor(0.1356, device='cuda:0')\n",
      "[ 9.3335974e-01  1.0611330e-01 -1.5971115e-01 ... -1.8545599e-03\n",
      " -1.6880536e-02  4.2876825e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 9.3335974e-01,  1.0611330e-01, -1.5971115e-01, ...,\n",
       "        -1.8545599e-03, -1.6880536e-02,  4.2876825e+00], dtype=float32)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prM,_= predict(model_onehot_L1, M)\n",
    "prM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3117.7268]], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances(prT, prF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[208.76878]], dtype=float32)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances(prT, prM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2959.233]], dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances(prF, prM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8656398]], dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(prT, prF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94269073]], dtype=float32)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(prT, prM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8808979]], dtype=float32)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(prF, prM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
